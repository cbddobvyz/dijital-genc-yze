{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f198e2e-b280-4ebe-b61f-8d7730df085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbddobvyz/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac549b22-6ca3-4239-8585-fcc96ac3d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoModelName = 'yolo11m.pt'\n",
    "ketemModelName = 'ketemYoloMedium.pt'\n",
    "dataYamlPath = 'data.yaml'\n",
    "projectFolder = 'objectDetection'\n",
    "trainingFolder = 'inbreastTraining'\n",
    "validationFolder = 'inbreastValidation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aefac86-5687-4315-a584-d63fe1f79af6",
   "metadata": {},
   "source": [
    "# DATA INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6025c5-5bbc-4d99-96cf-2dbcb0a8bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['MASS']\n"
     ]
    }
   ],
   "source": [
    "with open(dataYamlPath) as stream:\n",
    "    dataYamlDict = yaml.safe_load(stream)\n",
    "\n",
    "classes = dataYamlDict['names']\n",
    "class_size = len(classes)\n",
    "\n",
    "print('Class names:', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0a4c86-01c7-4ed0-9ecf-a6acbc0eaa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASS class counts in 87 images in TRAINING with 96 labels.\n"
     ]
    }
   ],
   "source": [
    "splitPath = dataYamlDict['train'].split(os.path.sep)\n",
    "splitPath[-1] = 'labels'\n",
    "\n",
    "trainLabelFolderPath = os.path.sep.join(splitPath)\n",
    "trainLabelFilePaths = glob.glob(os.path.join(trainLabelFolderPath, '*'))\n",
    "\n",
    "trainImageCounts = [0] * class_size\n",
    "totalLabelCounts = np.array([0] * class_size, dtype=int)\n",
    "\n",
    "for k in range(len(trainLabelFilePaths)):\n",
    "    \n",
    "    trainLabelFilePath = trainLabelFilePaths[k]\n",
    "    \n",
    "    fileContents = open(trainLabelFilePath, 'r')\n",
    "    labelCounts = np.array([0] * class_size)\n",
    "    for fileContent in fileContents:\n",
    "        data = fileContent.strip()\n",
    "        labelCounts[int(data[0])]+=1    \n",
    "    \n",
    "    totalLabelCounts += labelCounts    \n",
    "    \n",
    "    for j in range(len(labelCounts)):\n",
    "        if labelCounts[j]>0:\n",
    "            trainImageCounts[j]+=1\n",
    "            \n",
    "for i in range(len(trainImageCounts)):\n",
    "    print(classes[i], 'class counts in', trainImageCounts[i], 'images in TRAINING with', totalLabelCounts[i], 'labels.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abec6564-0242-4308-9f4c-267e114a5f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASS class counts in 20 images in TEST with 20 labels.\n"
     ]
    }
   ],
   "source": [
    "splitPath = dataYamlDict['val'].split(os.path.sep)\n",
    "splitPath[-1] = 'labels'\n",
    "\n",
    "testLabelFolderPath = os.path.sep.join(splitPath)\n",
    "testLabelFilePaths = glob.glob(os.path.join(testLabelFolderPath, '*'))\n",
    "\n",
    "testImageCounts = [0] * class_size\n",
    "totalLabelCounts = np.array([0] * class_size, dtype=int)\n",
    "\n",
    "for k in range(len(testLabelFilePaths)):\n",
    "    \n",
    "    testLabelFilePath = testLabelFilePaths[k]\n",
    "    \n",
    "    fileContents = open(testLabelFilePath, 'r')\n",
    "    labelCounts = np.array([0] * class_size)\n",
    "    for fileContent in fileContents:\n",
    "        data = fileContent.strip()\n",
    "        labelCounts[int(data[0])]+=1    \n",
    "    \n",
    "    totalLabelCounts += labelCounts    \n",
    "    \n",
    "    for j in range(len(labelCounts)):\n",
    "        if labelCounts[j]>0:\n",
    "            testImageCounts[j]+=1\n",
    "            \n",
    "for i in range(len(testImageCounts)):\n",
    "    print(classes[i], 'class counts in', testImageCounts[i], 'images in TEST with', totalLabelCounts[i], 'labels.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747a354-9df5-44f7-a5a4-8e140855f0c8",
   "metadata": {},
   "source": [
    "# Loading COCO PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c586ee3-fcc5-4167-ac23-e8b096cb6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoModel = YOLO(cocoModelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042afc4b-3b73-40d7-9515-415c1c16227a",
   "metadata": {},
   "source": [
    "## MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9340d5f-6b98-4e0e-a2f9-18980f16736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.55 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.51 ðŸš€ Python-3.10.12 torch-1.12.1+cu116 CUDA:0 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "                                                        CUDA:1 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11m.pt, data=data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1], workers=8, project=objectDetection, name=inbreastTrainingwithCOCO, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=objectDetection/inbreastTrainingwithCOCO\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLO11m summary: 409 layers, 20,053,779 parameters, 20,053,763 gradients, 68.2 GFLOPs\n",
      "\n",
      "Transferred 643/649 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 60095 /home/cbddobvyz/.config/Ultralytics/DDP/_temp_y76nk45t140224691164528.py\n",
      "Ultralytics 8.3.51 ðŸš€ Python-3.10.12 torch-1.12.1+cu116 CUDA:0 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "                                                        CUDA:1 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "Transferred 643/649 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/notebooks/webinar/data/Fold0/train/labels.cache... 87 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/notebooks/webinar/data/Fold0/validation/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to objectDetection/inbreastTrainingwithCOCO/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 16 dataloader workers\n",
      "Logging results to \u001b[1mobjectDetection/inbreastTrainingwithCOCO\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      4.55G      2.522      5.799      2.037          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20   0.000833       0.25     0.0019    0.00162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      4.59G      2.171      5.097      1.868          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.094       0.15     0.0272      0.018\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      4.75G      1.895      3.942      1.766          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.908      0.496      0.544      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      4.76G      1.438      2.558      1.404          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20          1      0.401      0.516      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30      4.75G      1.396      1.975        1.3          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.978        0.4      0.437      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      4.76G       1.46      1.602      1.278          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20          1      0.231       0.29      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      4.76G      1.314       1.59       1.22         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.767       0.35      0.379      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      4.76G      1.306      1.883      1.251          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.779        0.7      0.791      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      4.76G      1.273      1.408      1.105          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.776       0.45      0.538       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30      4.76G      1.219       1.23      1.145          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.875      0.349      0.455      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30      4.75G      1.309      1.208      1.205          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.914       0.75      0.817      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      4.76G      1.386      1.328       1.18          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.588      0.715      0.663       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30      4.76G      1.294      1.245      1.195         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.511       0.65      0.527       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      4.76G      1.165      1.152      1.156          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.655       0.45      0.528      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      4.76G      1.221      1.076      1.202          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.724      0.525      0.622      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      4.76G      1.321      1.128      1.207         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.485        0.5      0.463      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      4.76G      1.239       1.07      1.077         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.628       0.45      0.456       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      4.76G      1.307      1.101      1.281         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.682        0.8      0.698      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      4.75G      1.054     0.9019      1.082          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.687        0.8      0.756      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30      4.76G       1.27      0.954      1.218          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.687       0.85      0.744      0.437\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30      4.75G       1.01     0.8743      1.061          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.733       0.85      0.771      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      4.75G      1.066     0.9028      1.072          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.915       0.65      0.737      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      4.76G      1.129     0.9762      1.108          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.771        0.8      0.774      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      4.75G      1.001     0.8162      1.052          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.759      0.789      0.792      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      4.76G      1.031     0.7714      1.072          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.801       0.65       0.76      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      4.75G     0.9919     0.7053      1.015          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.823       0.75      0.768      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      4.75G     0.9585     0.6868      1.001          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.799      0.796      0.787      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      4.75G     0.8894     0.6763     0.9597          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.854      0.879       0.86      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30      4.76G     0.8732     0.6552     0.9636          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20       0.85        0.9      0.862      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      4.75G     0.8307     0.6411     0.9816          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.806        0.9      0.848      0.529\n",
      "\n",
      "30 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from objectDetection/inbreastTrainingwithCOCO/weights/last.pt, 40.5MB\n",
      "Optimizer stripped from objectDetection/inbreastTrainingwithCOCO/weights/best.pt, 40.5MB\n",
      "\n",
      "Validating objectDetection/inbreastTrainingwithCOCO/weights/best.pt...\n",
      "Ultralytics 8.3.51 ðŸš€ Python-3.10.12 torch-1.12.1+cu116 CUDA:0 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "                                                        CUDA:1 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.851        0.9      0.862      0.554\n",
      "Speed: 1.8ms preprocess, 3.3ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mobjectDetection/inbreastTrainingwithCOCO\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train the cocoModel\n",
    "cocoTrainResults = cocoModel.train(\n",
    "    data=dataYamlPath,  # path to dataset YAML\n",
    "    epochs=30,  # number of training epochs\n",
    "    imgsz=640,  # training image size\n",
    "    device=[0,1],  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
    "    project=projectFolder,\n",
    "    name=trainingFolder + 'withCOCO'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b72a1f0-c39f-4d1f-b476-49716b232dc7",
   "metadata": {},
   "source": [
    "## Metric Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786ae9e-8164-4865-9cc3-416fe84b0a89",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721811a5-7b9f-4cc9-9eb2-209009ce8df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.51 ðŸš€ Python-3.10.12 torch-1.12.1+cu116 CUDA:0 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "                                                        CUDA:1 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/notebooks/webinar/data/Fold0/validation/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.851        0.9      0.864      0.555\n",
      "Speed: 4.0ms preprocess, 6.4ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Saving objectDetection/inbreastValidationwithCOCO/predictions.json...\n",
      "Results saved to \u001b[1mobjectDetection/inbreastValidationwithCOCO\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cocoValidationResult = cocoModel.val(project=projectFolder, name=validationFolder + 'withCOCO', save_json=True, data=dataYamlPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9022ee-200b-4623-832e-3c72d60d3af5",
   "metadata": {},
   "source": [
    "#### Recall - Precision - AP - mAP Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cda5de6c-0f60-4a73-8269-e8b61d50d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASS Recall Value: 0.9\n",
      "MASS Precision Value: 0.8505999539642123\n",
      "MASS AP Value: 0.8641147706222079\n",
      "MASS mAP Value: 0.8641147706222079\n"
     ]
    }
   ],
   "source": [
    "for i, className in enumerate(classes):\n",
    "    print(className, 'Recall Value:', cocoValidationResult.box.r.tolist()[i])\n",
    "    print(className, 'Precision Value:', cocoValidationResult.box.p.tolist()[i])\n",
    "    print(className, 'AP Value:', cocoValidationResult.box.ap50.tolist()[i])\n",
    "    print(className, 'mAP Value:', cocoValidationResult.box.map50.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c7c37-1af0-4731-90b9-7573ed0f0e4d",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f239150-50dc-437d-8fa0-f264bb1690e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f887ca97190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(cv2.imread(os.path.join(cocoValidationResult.save_dir, 'confusion_matrix.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d76155bd-f97b-42df-a5eb-37beec0ebc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Count: [         18] False Positive Count: [          3] False Negative Count: [          2]\n"
     ]
    }
   ],
   "source": [
    "cocoTruePositiveCount, cocoFalsePositiveCount = cocoValidationResult.confusion_matrix.tp_fp()\n",
    "cocoFalseNegativeCount = totalLabelCounts - cocoTruePositiveCount\n",
    "print('True Positive Count:', cocoTruePositiveCount, 'False Positive Count:', cocoFalsePositiveCount, 'False Negative Count:', cocoFalseNegativeCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9631bd4-f399-4ae5-8f7f-ed53e8738403",
   "metadata": {},
   "source": [
    "### Speed Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e152f3d0-c719-4a01-91de-2a5059b1a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess Time: 3.9660215377807617\n",
      "Inference Time: 6.361150741577148\n",
      "Postprocess Time: 0.5598545074462891\n"
     ]
    }
   ],
   "source": [
    "print('Preprocess Time:', cocoValidationResult.speed['preprocess'])\n",
    "print('Inference Time:', cocoValidationResult.speed['inference'])\n",
    "print('Postprocess Time:', cocoValidationResult.speed['postprocess'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503f5e4-99c1-4537-8786-e4ba5053385a",
   "metadata": {},
   "source": [
    "## PREDICTIONS ON TEST DATA AND VISUALIZING MODEL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad81757c-6e53-4bac-a6af-973b01b2fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 MASS, 7.4ms\n",
      "1: 640x640 1 MASS, 7.4ms\n",
      "2: 640x640 (no detections), 7.4ms\n",
      "3: 640x640 2 MASSs, 7.4ms\n",
      "4: 640x640 1 MASS, 7.4ms\n",
      "5: 640x640 1 MASS, 7.4ms\n",
      "6: 640x640 1 MASS, 7.4ms\n",
      "7: 640x640 (no detections), 7.4ms\n",
      "8: 640x640 1 MASS, 7.4ms\n",
      "9: 640x640 2 MASSs, 7.4ms\n",
      "10: 640x640 1 MASS, 7.4ms\n",
      "11: 640x640 1 MASS, 7.4ms\n",
      "12: 640x640 1 MASS, 7.4ms\n",
      "13: 640x640 1 MASS, 7.4ms\n",
      "14: 640x640 3 MASSs, 7.4ms\n",
      "15: 640x640 1 MASS, 7.4ms\n",
      "16: 640x640 1 MASS, 7.4ms\n",
      "17: 640x640 1 MASS, 7.4ms\n",
      "18: 640x640 1 MASS, 7.4ms\n",
      "19: 640x640 2 MASSs, 7.4ms\n",
      "Speed: 4.1ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mobjectDetection/inbreastValidationPredswithCOCO\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cocoModelFilePath = os.path.join(projectFolder, trainingFolder + 'withCOCO', 'weights', 'best.pt')\n",
    "cocoModel = YOLO(cocoModelFilePath)\n",
    "cocoModelResults = cocoModel.predict(project=projectFolder, name=validationFolder+'PredswithCOCO', source=glob.glob(os.path.join(dataYamlDict['val'], '*')), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46543fc6-b41c-40da-8378-8c8c31ea9c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'MASS',\n",
       "  'class': 0,\n",
       "  'confidence': 0.72237,\n",
       "  'box': {'x1': 3038.61548, 'y1': 1227.81592, 'x2': 3328.0, 'y2': 1410.18811}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocoModelResults[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b2236e5-800d-45c8-9d88-c33607dbd0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([0.], device='cuda:0')\n",
       "conf: tensor([0.7224], device='cuda:0')\n",
       "data: tensor([[3.0386e+03, 1.2278e+03, 3.3280e+03, 1.4102e+03, 7.2237e-01, 0.0000e+00]], device='cuda:0')\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (4084, 3328)\n",
       "shape: torch.Size([1, 6])\n",
       "xywh: tensor([[3183.3076, 1319.0020,  289.3845,  182.3722]], device='cuda:0')\n",
       "xywhn: tensor([[0.9565, 0.3230, 0.0870, 0.0447]], device='cuda:0')\n",
       "xyxy: tensor([[3038.6155, 1227.8159, 3328.0000, 1410.1881]], device='cuda:0')\n",
       "xyxyn: tensor([[0.9130, 0.3006, 1.0000, 0.3453]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocoModelResults[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03fed95f-2df4-43ef-89b2-e5ec47f0faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f86cc8837f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileIndex = 1\n",
    "\n",
    "fileName = cocoModelResults[fileIndex].path.split(os.path.sep)[-1].split('.')[0]\n",
    "predImagePath = os.path.join(os.getcwd(), projectFolder, validationFolder+'PredswithCOCO', fileName + '.jpg')\n",
    "predImage = cv2.imread(predImagePath)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(predImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1f931-3a2f-4fbe-865d-4ae6c7c4906f",
   "metadata": {},
   "source": [
    "# Loading KETEM PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f243313d-8ad8-4acc-a947-11ff22743cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ketemModel = YOLO(ketemModelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d2963-8aae-4e48-b2d6-dba4d9e1ac05",
   "metadata": {},
   "source": [
    "## MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee234c81-6f85-4a42-b84d-c28ae1335c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.55 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.51 ðŸš€ Python-3.10.12 torch-1.12.1+cu116 CUDA:0 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "                                                        CUDA:1 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=ketemYoloMedium.pt, data=data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1], workers=8, project=objectDetection, name=inbreastTrainingwithKETEM, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=objectDetection/inbreastTrainingwithKETEM\n",
      "Overriding model.yaml nc=2 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLO11m summary: 409 layers, 20,053,779 parameters, 20,053,763 gradients, 68.2 GFLOPs\n",
      "\n",
      "Transferred 643/649 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 44967 /home/cbddobvyz/.config/Ultralytics/DDP/_temp_e3hl4nsw140216933818016.py\n",
      "Ultralytics 8.3.51 ðŸš€ Python-3.10.12 torch-1.12.1+cu116 CUDA:0 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "                                                        CUDA:1 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "Overriding model.yaml nc=2 with nc=1\n",
      "Transferred 643/649 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/notebooks/webinar/data/Fold0/train/labels.cache... 87 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/notebooks/webinar/data/Fold0/validation/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to objectDetection/inbreastTrainingwithKETEM/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 16 dataloader workers\n",
      "Logging results to \u001b[1mobjectDetection/inbreastTrainingwithKETEM\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      4.55G      1.429      4.469      1.228          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.001        0.3    0.00717    0.00476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      4.65G      1.311      4.186      1.099          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20       0.21       0.85      0.534      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      4.75G      1.341      3.613      1.189          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20          1       0.55      0.882      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      4.76G      1.308      2.886       1.19          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.912       0.95      0.964      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30      4.75G      1.308      2.553      1.105          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20       0.95      0.945      0.975       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      4.76G      1.344      2.299      1.134          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.889       0.95      0.981      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      4.76G      1.245      1.881      1.102         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.986        0.9      0.981      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      4.76G      1.242      1.826       1.12          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20          1       0.95      0.976      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      4.76G      1.103      1.538     0.9522          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.938        0.9      0.872      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30      4.76G     0.9656      1.431     0.9493          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.979       0.95       0.95      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30      4.76G      1.091      1.302      1.042          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.912       0.95      0.943      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      4.75G       1.24      1.725      1.042          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.854       0.95      0.924      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30      4.76G      1.008      1.234     0.9762         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.901       0.95       0.91       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      4.75G      1.081       1.27      1.032          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.891       0.95      0.932      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      4.76G      0.925     0.9527     0.9801          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.889       0.95      0.938      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      4.76G      1.126      1.177      1.051         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.947      0.889      0.894      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      4.76G      1.017      1.115     0.9479         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.931        0.9      0.887      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      4.76G      1.139      1.025      1.127         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.898        0.9      0.886      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      4.76G      0.953        1.1      1.025          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20        0.9        0.9       0.92      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30      4.75G      1.148     0.9903      1.019          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.888        0.9      0.908      0.587\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30      4.76G     0.8297     0.8749     0.9026          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20       0.89        0.9      0.904      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      4.75G      0.873     0.8648     0.9517          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.889        0.9      0.885      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      4.75G     0.8927     0.9442     0.9524          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.892        0.9      0.898      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      4.76G     0.8913     0.9039     0.9787          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.825      0.943      0.916      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      4.75G     0.9862     0.8638      1.003          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.816       0.95      0.913      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      4.76G     0.8871     0.7961      0.919          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.825       0.95      0.925      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      4.75G     0.9141     0.7925     0.9415          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.813       0.95      0.923      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      4.76G     0.8467     0.7832     0.8729          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.889       0.85      0.918      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30      4.75G     0.7896     0.7542     0.8967          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.889       0.85        0.9      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      4.75G     0.8532     0.7857     0.9391          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20      0.888       0.85      0.892       0.61\n",
      "\n",
      "30 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from objectDetection/inbreastTrainingwithKETEM/weights/last.pt, 40.5MB\n",
      "Optimizer stripped from objectDetection/inbreastTrainingwithKETEM/weights/best.pt, 40.5MB\n",
      "\n",
      "Validating objectDetection/inbreastTrainingwithKETEM/weights/best.pt...\n",
      "Ultralytics 8.3.51 ðŸš€ Python-3.10.12 torch-1.12.1+cu116 CUDA:0 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "                                                        CUDA:1 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20       0.95      0.947      0.975       0.66\n",
      "Speed: 1.7ms preprocess, 3.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mobjectDetection/inbreastTrainingwithKETEM\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train the cocoModel\n",
    "train_results = ketemModel.train(\n",
    "    data=dataYamlPath,  # path to dataset YAML\n",
    "    epochs=30,  # number of training epochs\n",
    "    imgsz=640,  # training image size\n",
    "    device=[0,1],  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
    "    project=projectFolder,\n",
    "    name=trainingFolder + 'withKETEM'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde0cc7-b948-41da-8767-d6ee525cd61a",
   "metadata": {},
   "source": [
    "## Metric Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db74bb17-1139-4ca8-99d2-501cec5fef98",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd6fea50-bdad-4cea-9be6-9c5649ed04f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.51 ðŸš€ Python-3.10.12 torch-1.12.1+cu116 CUDA:0 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "                                                        CUDA:1 (Tesla V100-SXM2-32GB, 32510MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/notebooks/webinar/data/Fold0/validation/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         20       0.95      0.944      0.978      0.664\n",
      "Speed: 3.0ms preprocess, 6.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Saving objectDetection/inbreastValidationwithKETEM/predictions.json...\n",
      "Results saved to \u001b[1mobjectDetection/inbreastValidationwithKETEM\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ketemValidationResult = ketemModel.val(project=projectFolder, name=validationFolder + 'withKETEM', save_json=True, data=dataYamlPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba46dcb-c79a-4383-8691-a5e196b4b793",
   "metadata": {},
   "source": [
    "#### Recall - Precision - AP - mAP Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46792b3f-1eea-4d13-8106-84bc1ee28de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASS Recall Value: [0.9436361208852634]\n",
      "MASS Precision Value: [0.9496650589939611]\n",
      "MASS AP Value: [0.9775]\n",
      "MASS mAP Value: 0.9775\n"
     ]
    }
   ],
   "source": [
    "for className in classes:\n",
    "    print(className, 'Recall Value:', ketemValidationResult.box.r.tolist())\n",
    "    print(className, 'Precision Value:', ketemValidationResult.box.p.tolist())\n",
    "    print(className, 'AP Value:', ketemValidationResult.box.ap50.tolist())\n",
    "    print(className, 'mAP Value:', ketemValidationResult.box.map50.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19ae22-c7ea-4f7b-bc62-090526e8377b",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3a32c96-2f3c-4a55-b577-67022edb1130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f886bd42140>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(cv2.imread(os.path.join(ketemValidationResult.save_dir, 'confusion_matrix.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13cb2590-5f4c-4817-99b2-cf883f2ebf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Count: [         19] False Positive Count: [          1] False Negative Count: [          1]\n"
     ]
    }
   ],
   "source": [
    "ketemTruePositiveCount, ketemFalsePositiveCount = ketemValidationResult.confusion_matrix.tp_fp()\n",
    "ketemFalseNegativeCount = totalLabelCounts - ketemTruePositiveCount\n",
    "print('True Positive Count:', ketemTruePositiveCount, 'False Positive Count:', ketemFalsePositiveCount, 'False Negative Count:', ketemFalseNegativeCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70bfe3-8e00-4ceb-83c3-115e7d62984f",
   "metadata": {},
   "source": [
    "### Speed Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66f6a37d-36ba-41a0-8d38-97040e6dc504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess Time: 3.0417323112487793\n",
      "Inference Time: 6.824588775634766\n",
      "Postprocess Time: 2.0153045654296875\n"
     ]
    }
   ],
   "source": [
    "print('Preprocess Time:', ketemValidationResult.speed['preprocess'])\n",
    "print('Inference Time:', ketemValidationResult.speed['inference'])\n",
    "print('Postprocess Time:', ketemValidationResult.speed['postprocess'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a7258-5617-4736-8b65-4e80ffcbc844",
   "metadata": {},
   "source": [
    "## PREDICTIONS ON TEST DATA AND VISUALIZING MODEL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0c13237-838d-4e0b-bee5-ad9a992ecb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 MASS, 7.0ms\n",
      "1: 640x640 1 MASS, 7.0ms\n",
      "2: 640x640 (no detections), 7.0ms\n",
      "3: 640x640 1 MASS, 7.0ms\n",
      "4: 640x640 1 MASS, 7.0ms\n",
      "5: 640x640 1 MASS, 7.0ms\n",
      "6: 640x640 1 MASS, 7.0ms\n",
      "7: 640x640 1 MASS, 7.0ms\n",
      "8: 640x640 1 MASS, 7.0ms\n",
      "9: 640x640 1 MASS, 7.0ms\n",
      "10: 640x640 1 MASS, 7.0ms\n",
      "11: 640x640 1 MASS, 7.0ms\n",
      "12: 640x640 1 MASS, 7.0ms\n",
      "13: 640x640 1 MASS, 7.0ms\n",
      "14: 640x640 1 MASS, 7.0ms\n",
      "15: 640x640 1 MASS, 7.0ms\n",
      "16: 640x640 1 MASS, 7.0ms\n",
      "17: 640x640 1 MASS, 7.0ms\n",
      "18: 640x640 1 MASS, 7.0ms\n",
      "19: 640x640 1 MASS, 7.0ms\n",
      "Speed: 6.7ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mobjectDetection/inbreastValidationPredswithKETEM\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ketemModelFilePath = os.path.join(projectFolder, trainingFolder + 'withKETEM', 'weights', 'best.pt')\n",
    "ketemModel = YOLO(ketemModelFilePath)\n",
    "ketemModelResults = ketemModel.predict(project=projectFolder, name=validationFolder+'PredswithKETEM', source=glob.glob(os.path.join(dataYamlDict['val'], '*')), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55ce3716-5fc3-4ed5-9852-5d21a75dd78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'MASS',\n",
       "  'class': 0,\n",
       "  'confidence': 0.73649,\n",
       "  'box': {'x1': 3040.53735, 'y1': 1218.45471, 'x2': 3328.0, 'y2': 1414.08801}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ketemModelResults[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a07066c1-ef0a-444b-95ab-d2a0f1ffef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([0.], device='cuda:0')\n",
       "conf: tensor([0.7365], device='cuda:0')\n",
       "data: tensor([[3.0405e+03, 1.2185e+03, 3.3280e+03, 1.4141e+03, 7.3649e-01, 0.0000e+00]], device='cuda:0')\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (4084, 3328)\n",
       "shape: torch.Size([1, 6])\n",
       "xywh: tensor([[3184.2686, 1316.2714,  287.4626,  195.6333]], device='cuda:0')\n",
       "xywhn: tensor([[0.9568, 0.3223, 0.0864, 0.0479]], device='cuda:0')\n",
       "xyxy: tensor([[3040.5374, 1218.4547, 3328.0000, 1414.0880]], device='cuda:0')\n",
       "xyxyn: tensor([[0.9136, 0.2983, 1.0000, 0.3463]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ketemModelResults[0].boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd8618-d3b8-4697-8bba-23c876c6f5ab",
   "metadata": {},
   "source": [
    "## Benchmarking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "265af5b4-288e-4125-bcdc-a196d9d7ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASS Recall Value in KETEM Pretrained: 0.944 Recall Value in COCO Pretrained: 0.9\n",
      "MASS Precision Value in KETEM Pretrained: 0.95 Precision Value in COCO Pretrained: 0.851\n",
      "MASS AP Value in KETEM Pretrained: 0.978 AP Value in COCO Pretrained: 0.864\n",
      "MASS mAP Value in KETEM Pretrained: 0.978 mAP Value in COCO Pretrained: 0.864\n"
     ]
    }
   ],
   "source": [
    "for i, className in enumerate(classes):\n",
    "    print(className, 'Recall Value in KETEM Pretrained:', round(ketemValidationResult.box.r.tolist()[i],3), 'Recall Value in COCO Pretrained:', round(cocoValidationResult.box.r.tolist()[i],3))\n",
    "    print(className, 'Precision Value in KETEM Pretrained:', round(ketemValidationResult.box.p.tolist()[i],3), 'Precision Value in COCO Pretrained:', round(cocoValidationResult.box.p.tolist()[i],3))\n",
    "    print(className, 'AP Value in KETEM Pretrained:', round(ketemValidationResult.box.ap50.tolist()[i],3), 'AP Value in COCO Pretrained:', round(cocoValidationResult.box.ap50.tolist()[i],3))\n",
    "    print(className, 'mAP Value in KETEM Pretrained:', round(ketemValidationResult.box.map50.tolist(),3), 'mAP Value in COCO Pretrained:', round(cocoValidationResult.box.map50.tolist(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07238701-c83e-4b66-8496-a03211c9df5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KETEM Recall</th>\n",
       "      <th>COCO Recall</th>\n",
       "      <th>KETEM Precision</th>\n",
       "      <th>COCO Precision</th>\n",
       "      <th>KETEM FPPI</th>\n",
       "      <th>COCO FPPI</th>\n",
       "      <th>KETEM AP</th>\n",
       "      <th>COCO AP</th>\n",
       "      <th>KETEM mAP</th>\n",
       "      <th>COCO mAP</th>\n",
       "      <th>KETEM TP</th>\n",
       "      <th>COCO TP</th>\n",
       "      <th>KETEM FP</th>\n",
       "      <th>COCO FP</th>\n",
       "      <th>KETEM FN</th>\n",
       "      <th>COCO FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MASS</th>\n",
       "      <td>0.943636</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.949665</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.864115</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.864115</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      KETEM Recall  COCO Recall  KETEM Precision  COCO Precision  KETEM FPPI  \\\n",
       "MASS      0.943636          0.9         0.949665          0.8506        0.05   \n",
       "\n",
       "      COCO FPPI  KETEM AP   COCO AP  KETEM mAP  COCO mAP  KETEM TP  COCO TP  \\\n",
       "MASS       0.15    0.9775  0.864115     0.9775  0.864115      19.0     18.0   \n",
       "\n",
       "      KETEM FP  COCO FP  KETEM FN  COCO FN  \n",
       "MASS       1.0      3.0       1.0      2.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfData = {\n",
    "    'KETEM Recall': ketemValidationResult.box.r.tolist(),\n",
    "    'COCO Recall': cocoValidationResult.box.r.tolist(),\n",
    "    'KETEM Precision': ketemValidationResult.box.p.tolist(),\n",
    "    'COCO Precision': cocoValidationResult.box.p.tolist(),\n",
    "    'KETEM FPPI': ketemFalsePositiveCount/np.array(testImageCounts),\n",
    "    'COCO FPPI': cocoFalsePositiveCount/np.array(testImageCounts),\n",
    "    'KETEM AP': ketemValidationResult.box.ap50.tolist(),\n",
    "    'COCO AP': cocoValidationResult.box.ap50.tolist(),\n",
    "    'KETEM mAP': [ketemValidationResult.box.map50.tolist()],\n",
    "    'COCO mAP': [cocoValidationResult.box.map50.tolist()],\n",
    "    'KETEM TP': ketemTruePositiveCount,\n",
    "    'COCO TP': cocoTruePositiveCount,\n",
    "    'KETEM FP': ketemFalsePositiveCount,\n",
    "    'COCO FP': cocoFalsePositiveCount,\n",
    "    'KETEM FN': ketemFalseNegativeCount,\n",
    "    'COCO FN': cocoFalseNegativeCount,\n",
    "}\n",
    "benchmarkDf = pd.DataFrame(data=dfData, index=classes)\n",
    "benchmarkDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af5bce86-6eff-4715-b722-362ccb16cc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FPPI</th>\n",
       "      <th>AP</th>\n",
       "      <th>mAP</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KETEM</th>\n",
       "      <td>0.943636</td>\n",
       "      <td>0.949665</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COCO</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.850600</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.864115</td>\n",
       "      <td>0.864115</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Recall  Precision  FPPI        AP       mAP    TP   FP   FN\n",
       "KETEM  0.943636   0.949665  0.05  0.977500  0.977500  19.0  1.0  1.0\n",
       "COCO   0.900000   0.850600  0.15  0.864115  0.864115  18.0  3.0  2.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ketemValResultList = [ketemValidationResult.box.r.tolist()[0],\n",
    "                     ketemValidationResult.box.p.tolist()[0],\n",
    "                     (ketemFalsePositiveCount/np.array(testImageCounts))[0],\n",
    "                     ketemValidationResult.box.ap50.tolist()[0],\n",
    "                     ketemValidationResult.box.map50.tolist(),\n",
    "                     ketemTruePositiveCount[0],\n",
    "                     ketemFalsePositiveCount[0],\n",
    "                     ketemFalseNegativeCount[0]\n",
    "                    ]\n",
    "cocoValResultList = [cocoValidationResult.box.r.tolist()[0],\n",
    "                     cocoValidationResult.box.p.tolist()[0],\n",
    "                     (cocoFalsePositiveCount/np.array(testImageCounts))[0],\n",
    "                     cocoValidationResult.box.ap50.tolist()[0],\n",
    "                     cocoValidationResult.box.map50.tolist(),\n",
    "                     cocoTruePositiveCount[0],\n",
    "                     cocoFalsePositiveCount[0],\n",
    "                     cocoFalseNegativeCount[0]\n",
    "                    ]\n",
    "benchmarkDf = pd.DataFrame(data=[ketemValResultList, cocoValResultList], index=['KETEM', 'COCO'], columns=['Recall', 'Precision', 'FPPI', 'AP', 'mAP', 'TP', 'FP', 'FN'])\n",
    "benchmarkDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f4f73a-d445-4834-ac95-872fc1dfdc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
